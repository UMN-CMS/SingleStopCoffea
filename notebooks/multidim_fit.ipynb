{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b9e7bc27-3d7d-4df4-bea5-8d7880f278ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "a554f2de-7dc8-44ab-a0f1-8ab8354493ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle as pkl\n",
    "import hist\n",
    "from analyzer.datasets import SampleManager\n",
    "from analyzer.core import AnalysisResult\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch.masked import masked_tensor, as_masked_tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c91e9-0918-4807-b2bb-623f72768d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6a6ae239-3445-438c-8f8c-8105c483f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from analyzer.plotting.plots_1d import drawAs1DHist\n",
    "from analyzer.plotting.plots_2d import drawAs2DHist, addTitles2D\n",
    "from analyzer.plotting.plottables import PlotObject\n",
    "from analyzer.plotting.mplstyles import loadStyles\n",
    "import analyzer.plotting as plot\n",
    "loadStyles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f39974c3-b875-4a1f-8722-2e9dd86b24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitting import regression\n",
    "from fitting import plot_tools as fplt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "454420b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = AnalysisResult.fromFile(\"../results/data_control.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "fa1055ef-32c5-4437-acba-0e68bccd6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_manager = SampleManager()\n",
    "sample_manager.loadSamplesFromDirectory(\"../datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c67df913-915e-4a18-8d5f-5f2c6cc5bf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<div style=\"display:flex; align-items:center;\">\n",
       "<div style=\"width:290px;\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"-20 -270 290 290\">\n",
       "<text text-anchor=\"middle\" x=\"0\" y=\"13\" style=\"fill:currentColor;\">\n",
       "0\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"13\" style=\"fill:currentColor;\">\n",
       "1\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"-10\" y=\"0\" style=\"fill:currentColor;\">\n",
       "0\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"-10\" y=\"-250\" style=\"fill:currentColor;\">\n",
       "10\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"125.0\" y=\"13\" style=\"fill:currentColor;\">\n",
       "Primary dataset\n",
       "</text>\n",
       "<text text-anchor=\"middle\" x=\"-10\" y=\"-125.0\" transform=\"rotate(-90,-10,-125.0)\" style=\"fill:currentColor;\">\n",
       "$n_{j}$\n",
       "</text>\n",
       "<rect x=\"0.0\" y=\"-25.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-50.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-75.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-100.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-125.0\" width=\"250.0\" height=\"25.0\" opacity=\"1.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-150.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.5352967448637913\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-175.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.21694736789576377\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-200.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-225.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "<rect x=\"0.0\" y=\"-250.0\" width=\"250.0\" height=\"25.0\" opacity=\"0.0\" fill=\"currentColor\" stroke-width=\"0.1\"/>\n",
       "</svg>\n",
       "</div>\n",
       "<div style=\"flex=grow:1;\">\n",
       "StrCategory(['CR0b_Data2018'], growth=True, name='dataset', label='Primary dataset')<br/>\n",
       "Regular(10, 0, 10, name='nj', label='$n_{j}$')<br/>\n",
       "<hr style=\"margin-top:.2em; margin-bottom:.2em;\"/>\n",
       "Weight() Î£=WeightedSum(value=1.40454e+07, variance=1.40454e+07)\n",
       "\n",
       "</div>\n",
       "</div>\n",
       "</html>"
      ],
      "text/plain": [
       "Hist(\n",
       "  StrCategory(['CR0b_Data2018'], growth=True, name='dataset', label='Primary dataset'),\n",
       "  Regular(10, 0, 10, name='nj', label='$n_{j}$'),\n",
       "  storage=Weight()) # Sum: WeightedSum(value=1.40454e+07, variance=1.40454e+07)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.results[\"CR0b_Data2018\"].histograms[\"h_njet\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ad036334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hists = res.getMergedHistograms(sample_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e5b63-4053-4fc8-bbe8-29f1fd277fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f3ead402-abf4-421e-bf60-081ebff6ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_name=\"CR0b_Data2018\"\n",
    "complete_hist = hists[\"ratio_m14_vs_m24\"]\n",
    "narrowed = complete_hist\n",
    "#orig =  complete_hist[...,hist.loc(1100):hist.loc(2500),hist.loc(400):hist.loc(2000)]\n",
    "#narrowed =  complete_hist[...,hist.loc(0):hist.loc(3000),hist.loc(0):hist.loc(1)]\n",
    "narrowed =  complete_hist[...,hist.loc(1150):hist.loc(3000),hist.loc(0.4):hist.loc(1)]\n",
    "#orig = orig / orig.values().max()\n",
    "#orig =  complete_hist[...,hist.loc(1150):hist.loc(3000),hist.loc(400):hist.loc(3000)]#orig =  complete_hist[...,hist.loc(0):hist.loc(3000),hist.loc(0):hist.loc(3000)]\n",
    "#narrowed = orig\n",
    "#narrowed = orig[...,::hist.rebin(15),::hist.rebin(12)]\n",
    "narrowed = narrowed[...,::hist.rebin(1),::hist.rebin(1)]\n",
    "\n",
    "qcd_hist = narrowed[bkg_name,...]\n",
    "#orig_qcd_hist = orig[bkg_name,...]\n",
    "\n",
    "#sig_hist = narrowed[\"signal_312_1500_900\",...]\n",
    "\n",
    "qcd_hist = narrowed[bkg_name,...] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "eca318b1-9bd7-47f9-938b-6a6adfa8fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.384642899725766e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataValues' object has no attribute 'variances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[391], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m qcd_hist \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m value_scale\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mvariances()\u001b[38;5;241m.\u001b[39mmax())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariances\u001b[49m\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataValues' object has no attribute 'variances'"
     ]
    }
   ],
   "source": [
    "x = qcd_hist * 1 / value_scale.item()\n",
    "print(x.variances().max())\n",
    "print(train.variances.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168a6c1-9d37-485a-b334-58584668aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e5ddd-573d-45f9-ae99-9e885d995cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def addColorbar(ax, vals):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(vals, cax=cax)\n",
    "    cax.get_yaxis().set_offset_position(\"left\")\n",
    "    ax.cax = cax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efeac79-b579-40c7-964c-24a5c00b250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(1,2,figsize=(10,3))\n",
    "_ = drawAs2DHist(ax[0], PlotObject.fromHist(qcd_hist))\n",
    "#_ = drawAs2DHist(ax[1], PlotObject.fromHist(sig_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbaed9f-bcfd-4fc3-b880-348f355b7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [(1300, 1550), (0.46, 0.6)]\n",
    "\n",
    "train_data = regression.makeRegressionData(qcd_hist[hist.rebin(1),hist.rebin(1)], window, exclude_less=1)\n",
    "test_data = regression.makeRegressionData(qcd_hist[hist.rebin(1),hist.rebin(1)], None, exclude_less=1)\n",
    "\n",
    "train_transform = regression.getNormalizationTransform(train_data)\n",
    "test_transform = regression.getNormalizationTransform(test_data)\n",
    "\n",
    "normalized_train_data = train_transform.transform(train_data)\n",
    "normalized_test_data = test_transform.transform(test_data)\n",
    "\n",
    "print(train_transform)\n",
    "print(test_transform)\n",
    "print(train_data.X[:10])\n",
    "print(test_data.X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175f522-cd2c-42f6-a29c-244c768872f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(10,10),layout=\"tight\")\n",
    "fplt.simpleGrid(ax[0][0], train_data.E, train_data.X, train_data.Y)\n",
    "fplt.simpleGrid(ax[0][1], test_data.E, test_data.X, test_data.Y)\n",
    "fplt.simpleGrid(ax[1][0], normalized_train_data.E, normalized_train_data.X, normalized_train_data.Y)\n",
    "fplt.simpleGrid(ax[1][1], normalized_test_data.E, normalized_test_data.X, normalized_test_data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109ff73-f043-4238-8194-47fd84f3dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self, odim=2):\n",
    "        super().__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(2, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, odim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438f060-6e83-473e-a785-86ed7ccf1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, train_x, train_y, likelihood,kernel=None,odim=2):\n",
    "            super().__init__(train_x, train_y, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            \n",
    "            self.covar_module = kernel or gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2))\n",
    "            feature_extractor = LargeFeatureExtractor(odim=odim)\n",
    "            self.feature_extractor = feature_extractor\n",
    "\n",
    "            # This module will scale the NN features so that they're nice values\n",
    "            self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # We're first putting our data through a deep net (feature extractor)\n",
    "            projected_x = self.feature_extractor(x)\n",
    "            projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\n",
    "\n",
    "            mean_x = self.mean_module(projected_x)\n",
    "            covar_x = self.covar_module(projected_x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1186a7-fa73-4909-b57a-be8f4cb2c932",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fitting import regression\n",
    "from gpytorch.kernels import ScaleKernel as SK\n",
    "from gpytorch.kernels import RBFKernel as RBF\n",
    "\n",
    "import fitting.models as models\n",
    "#importlib.reload(models)\n",
    "#importlib.reload(regression)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():   \n",
    "    print(\"Loading train to gpu\")\n",
    "    train = regression.DataValues(normalized_train_data.X.cuda(), normalized_train_data.Y.cuda(), normalized_train_data.V.cuda(), None)\n",
    "    print(\"Loaded train to gpu\")\n",
    "else:\n",
    "    train = normalized_train_data\n",
    "    \n",
    "\n",
    "\n",
    "# model,likelihood = regression.createModel(\n",
    "#     train_data, \n",
    "#     kernel=SK(\n",
    "#         gpytorch.kernels.GridInterpolationKernel(\n",
    "#             gpytorch.kernels.RBFKernel(ard_num_dims=2), grid_size=grid_size, num_dims=2)\n",
    "#     ))\n",
    "#model,likelihood = regression.createModel(train_data, \n",
    "#kernel=SK(\n",
    "#                                              gpytorch.kernels.RBFKernel(ard_num_dims=2) + \n",
    "#                                              gpytorch.kernels.LinearKernel(ard_num_dims=2,num_dimensions=2)\n",
    "#                                          ))\n",
    "#model,likelihood = regression.createModel(train_data, kernel=SK(gpytorch.kernels.MaternKernel(ard_num_dims=2)))\n",
    "#model,likelihood = regression.createModel(train_data, kernel=SK(gpytorch.kernels.PiecewisePolynomialKernel(ard_num_dims=2)))\n",
    "#model,likelihood = regression.createModel(train_data, model_maker= ExactProjGPModel )#model,likelihood = regression.createModel(train, kernel=SK(models.MatrixRBF()))\n",
    "#model,likelihood = regression.createModel(train_data, kernel=SK(models.PeakedRBF(ard_num_dims=2)))\n",
    "#known_mean = models.HeterogenousConstantMean(train_data.Y)\n",
    "\n",
    "smk = gpytorch.kernels.SpectralMixtureKernel(ard_num_dims=2, num_mixtures=4)\n",
    "gsmk=models.GeneralSpectralMixture(num_mixtures=1, ard_num_dims=2)\n",
    "smk.initialize_from_data(train.X, train.Y)\n",
    "#gsmk.initialize_from_data(train.inputs, train.outputs)\n",
    "\n",
    "grbf = models.GeneralRBF(ard_num_dims=2)\n",
    "lk = gpytorch.kernels.LinearKernel(ard_num_dims=2,num_dimensions=2)\n",
    "rbf = gpytorch.kernels.RBFKernel(ard_num_dims=2)\n",
    "\n",
    "#model,likelihood = regression.createModel(train, kernel=gpytorch.kernels.SpectralMixtureKernel(ard_num_dims=2, num_mixtures=2))\n",
    "#model,likelihood = regression.createModel(train, kernel=smk)\n",
    "#model,likelihood = regression.createModel(train, model_maker=NNModel, kernel=rbf, odim=2)\n",
    "#model,likelihood = regression.createModel(train, kernel=induc_grbf, mean=None, learn_noise=False)\n",
    "\n",
    "#model,likelihood = regression.createModel(train, kernel=gpytorch.kernels.SpectralDeltaKernel(num_dims=2, ard_num_dims=2))#model,likelihood = regression.createModel(train, kernel=SK(gpytorch.kernels.RQKernel(ard_num_dims=2)))\n",
    "#model,likelihood = regression.createModel(train, kernel=SK(models.GeneralRBF(ard_num_dims=2)))\n",
    "#model,likelihood = regression.createModel(train, kernel=SK(models.GeneralRQ(ard_num_dims=2)))\n",
    "#model,likelihood = regression.createModel(train, kernel=models.GeneralSpectralMixture(num_mixtures=1, ard_num_dims=2))\n",
    "#model,likelihood = regression.createModel(train, kernel=grbf)\n",
    "print(model)\n",
    "def create4Part(k,*args,**kwargs):\n",
    "    return ( k(*args,**kwargs,ard_num_dims=2,active_dims=(0,0))\n",
    "          *k(*args,**kwargs,ard_num_dims=2,active_dims=(1,0))            \n",
    "          *k(*args,**kwargs,ard_num_dims=2,active_dims=(0,1))\n",
    "          *k(*args,**kwargs,ard_num_dims=2,active_dims=(1,1))\n",
    "           )\n",
    "#model.covar_module.kernels[1].initialize_from_data(train.inputs, train.outputs)\n",
    "#model.covar_module.base_kernel.initialize_from_data(train.inputs, train.outputs)\n",
    "#model.covar_module.initialize_from_data_empspect(train.inputs, train.outputs)\n",
    "\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(\n",
    "        noise=train.V,\n",
    "        learn_additional_noise=False,\n",
    "    )\n",
    "rbf4 = create4Part(gpytorch.kernels.RBFKernel)\n",
    "\n",
    "#model,likelihood = regression.createModel(train, kernel=rbf4)\n",
    "\n",
    "\n",
    "class InducingPointModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, inducing):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.base_covar_module = rbf4\n",
    "        self.covar_module = gpytorch.kernels.InducingPointKernel(self.base_covar_module, inducing_points=inducing.clone(), likelihood=likelihood)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "model = InducingPointModel(train.X,train.Y, likelihood, train.X[::2])\n",
    "if torch.cuda.is_available():   \n",
    "    print(\"Loading model to gpu\")\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    #train = regression.DataValues(train.inputs.cuda(), train.outputs.cuda(), train.variances.cuda(), None)\n",
    "    print(\"Loaded model to gpu\")\n",
    "    \n",
    "model,likelihood = regression.optimizeHyperparams(model,likelihood, train, bar=False, iterations=400, lr=0.1)\n",
    "\n",
    "for n,p in model.named_parameters():    \n",
    "    print(f\"{n:45} {p.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706129b-00d5-4de2-830e-e60aa0b14fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.covar_module.base_kernel.getMatrix())\n",
    "print(model.covar_module.base_kernel.rot)\n",
    "print(model.covar_module.base_kernel.lengthscale)\n",
    "#print(model.covar_module.getMatrix())\n",
    "#print(model.covar_module.rot)\n",
    "#print(model.covar_module.lengthscale)\n",
    "\n",
    "\n",
    "\n",
    "#print(model.covar_module.base_kernel.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75772135-41d7-48f5-911f-e65edf9d2e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ab9cb-a86a-459d-a851-c80854aae2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import linear_operator\n",
    "#with linear_operator.settings.max_cg_iterations(10000):\n",
    "#    pred = regression.getPrediction(model, likelihood, test_data)\n",
    "pred = regression.getPrediction(model, likelihood, normalized_test_data)\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import itertools as it\n",
    "from fitting.plot_tools import simpleGrid\n",
    "#window = [(1300,1550),(400,600)]\n",
    "print(test_transform)\n",
    "pred = test_transform.iTransform(\n",
    "    regression.DataValues(normalized_test_data.X, pred.mean, pred.variance, normalized_test_data.E))\n",
    "\n",
    "\n",
    "if window:\n",
    "    print(regression.getChi2Blinded(pred.X, pred.Y, test_data.Y, test_data.V, window))\n",
    "\n",
    "all_pulls = (pred.Y - test_data.Y) / torch.sqrt(test_data.V)\n",
    "all_x2 = (pred.Y - test_data.Y)**2 / test_data.V\n",
    "x2 = torch.sum(all_x2)\n",
    "\n",
    "def addColorbar(ax, vals):\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(vals, cax=cax)\n",
    "    cax.get_yaxis().set_offset_position(\"left\")\n",
    "    ax.cax = cax\n",
    "\n",
    "fig, ax=plt.subplots(layout=\"tight\")\n",
    "f = simpleGrid(ax, train_data.E, train_data.X, train_data.Y)\n",
    "ax.set_title(\"Masked Inputs (Training)\")\n",
    "addTitles2D(ax, PlotObject.fromHist(qcd_hist))\n",
    "#fig.savefig(figpath / \"training_points.pdf\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "f = simpleGrid(ax, pred.E, pred.X, pred.Y)\n",
    "ax.set_title(\"GPR Mean Prediction\")\n",
    "addTitles2D(ax, PlotObject.fromHist(qcd_hist))\n",
    "#fig.savefig(figpath / \"gpr_mean.pdf\")\n",
    "\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "f = simpleGrid(ax, test_data.E, test_data.X, test_data.Y)\n",
    "ax.set_title(\"Observed Outputs\")\n",
    "#fig.savefig(figpath / \"observed_outputs.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "#drawAs2DHist(ax[1,1], PlotObject.fromHist(sig_hist))\n",
    "#addTitles2D(ax[1,1], PlotObject.fromHist(sig_hist))\n",
    "#ax[1,1].set_title(\"Signal MC\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "f = simpleGrid(ax, test_data.E, test_data.X, test_data.V)\n",
    "ax.set_title(\"Observed Variances\")\n",
    "addTitles2D(ax, PlotObject.fromHist(qcd_hist))\n",
    "\n",
    "#fig.savefig(figpath / \"observed_variances.pdf\")\n",
    "\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "f = simpleGrid(ax, pred.E, pred.X, pred.V)\n",
    "ax.set_title(\"Pred Variances\")\n",
    "addTitles2D(ax, PlotObject.fromHist(qcd_hist))\n",
    "\n",
    "#fig.savefig(figpath / \"predicted_variances.pdf\")\n",
    "\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "f = simpleGrid(ax, test_data.E, test_data.X, (test_data.Y - pred.Y)/ torch.sqrt(test_data.V))\n",
    "f.set_clim(-5,5)\n",
    "ax.set_title(\"Pulls\")\n",
    "addTitles2D(ax, PlotObject.fromHist(qcd_hist))\n",
    "ax.cax.set_ylabel(r\"$\\frac{N_{obs}-N_{pred}}{\\sigma_{p}}$\")\n",
    "#fig.savefig(figpath / \"pulls.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "import uhi\n",
    "fig, ax=plt.subplots(figsize=(10,10), layout=\"tight\")\n",
    "p = PlotObject.fromHist(uhi.numpy_plottable.ensure_plottable_histogram(np.histogram(all_pulls[torch.abs(all_pulls) < np.inf], bins=20)))\n",
    "drawAs1DHist(ax, p, yerr=False)\n",
    "ax.set_xlabel(r\"$\\frac{N_{obs}-N_{pred}}{\\sigma_{o}}$\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "#fig.savefig(figpath / \"pulls_hist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13ce1f-ab59-4920-9320-edcb9b50aa34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fitting.plot_tools as fpt\n",
    "import fitting\n",
    "import analyzer.plotting as plotting\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "importlib.reload(fpt)\n",
    "dim = 1\n",
    "\n",
    "pred_mean,_ = fitting.regression.pointsToGrid(test_data.X, pred.Y, test_data.E)\n",
    "pred_var,_ = fitting.regression.pointsToGrid(test_data.X, pred.V, test_data.E)\n",
    "obs_vals,_ = fitting.regression.pointsToGrid(test_data.X, test_data.Y, test_data.E)\n",
    "obs_vars, filled = fitting.regression.pointsToGrid(test_data.X, test_data.V, test_data.E)\n",
    "\n",
    "#(figpath /\"slices\" / f\"along_{dim}\").mkdir(parents=True, exist_ok=True)\n",
    "for val, f, ax in fpt.createSlices(\n",
    "    pred_mean.hist,\n",
    "    pred_var.hist,\n",
    "    obs_vals.hist,\n",
    "    obs_vars.hist,\n",
    "    test_data.E,\n",
    "    filled,\n",
    "    observed_title=\"CRData\", window_2d=window, dim=dim):\n",
    "    plotting.addTitles1D(ax, plotting.PlotObject.fromHist(qcd_hist[:,sum]))\n",
    "    #f.savefig(figpath /\"slices\" / f\"along_{dim}\" /  (f\"slice_{round(float(val),3)}\".replace(\".\",\"p\") + \".pdf\"))\n",
    "    #plt.close(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82709559-6efd-438a-a5a4-e4582986874f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52fb6f-6815-4d1f-9b57-176799f4a536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795164d1-fa67-4d24-bf8b-d0234cd8aa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178f24e-702a-4b91-bce2-d8ee40c253a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsmlenv",
   "language": "python",
   "name": "cmsmlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
