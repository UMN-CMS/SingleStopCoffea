distributed:
  dashboard:
    link:  "{scheme}://{host}:{port}/status"
  worker:
    profile:
      enabled: true
  nanny:
    environ:
      MALLOC_TRIM_THRESHOLD_: 0
jobqueue:
  lpccondor:
    name: dask-worker

    # Dask worker options
    cores: 1                 # Total number of cores per job
    memory: 2GB                # Total amount of memory per job
    processes: 1                # Number of Python processes per job
    threads: 1

    interface: null             # Network interface to use like eth0 or ib0
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    local-directory: /srv       # Location of fast local storage like /scratch or $TMPDIR
    shared-temp-directory: null
    extra: null

    worker-extra-args:
      - "--worker-port 10000:10070"
      - "--nanny-port 10071:10100"
      #- "--no-dashboard"

    # HTCondor Resource Manager options
    disk: 200MB                  # Total amount of disk per job
    job-extra: {}               # Extra submit attributes
    log-directory: null
    env-extra: null
    job-script-prologue:
      - 'tar xzf environment.tar.gz'
      - 'source setup.sh coffea bashrc'
      - export X509_USER_PROXY=$(realpath $(find . -iname 'x509*'))
      - echo 'X509 Is'
      - echo $X509_USER_PROXY

    job-extra: null             # Extra submit attributes
    job-extra-directives: {}
    job-directives-skip: []
    submit-command-extra: []    # Extra condor_submit arguments
    cancel-command-extra: []    # Extra condor_rm arguments
    log-directory: null
    shebang: "#!/usr/bin/env condor_submit" # doesn't matter
    
    # Scheduler options
    scheduler-options: {}
